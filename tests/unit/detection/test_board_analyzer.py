"""
Unit tests for BoardAnalyzer.

This module tests the board state analysis functionality that determines
optimal Marcus modes and analyzes project organization level.

Notes
-----
All external dependencies are mocked to ensure isolated unit testing.
Tests cover normal operations, edge cases, and error scenarios.
"""

import pytest
from datetime import datetime, timedelta
from typing import List
from unittest.mock import Mock, AsyncMock, patch
import re

from src.detection.board_analyzer import (
    BoardAnalyzer, BoardState, WorkflowPattern
)
from src.core.models import Task, TaskStatus, Priority


class TestBoardAnalyzer:
    """
    Test suite for the BoardAnalyzer class.
    
    Tests board analysis capabilities including structure scoring,
    workflow pattern detection, phase/component detection, and mode recommendations.
    """
    
    @pytest.fixture
    def analyzer(self) -> BoardAnalyzer:
        """Create a BoardAnalyzer instance for testing."""
        return BoardAnalyzer()
    
    @pytest.fixture
    def basic_task(self) -> Task:
        """Create a basic task with minimal fields."""
        return Task(
            id="TASK-001",
            name="Basic task",
            description="",
            status=TaskStatus.TODO,
            priority=Priority.MEDIUM,
            assigned_to=None,
            created_at=datetime.now(),
            updated_at=datetime.now(),
            due_date=None,
            estimated_hours=0.0,
            dependencies=[],
            labels=[]
        )
    
    @pytest.fixture
    def well_structured_task(self) -> Task:
        """Create a well-structured task with all metadata."""
        return Task(
            id="TASK-002",
            name="Implement user authentication",
            description="Add OAuth2 authentication with Google and GitHub providers. "
                       "This includes creating the login UI, backend integration, and session management.",
            status=TaskStatus.IN_PROGRESS,
            priority=Priority.HIGH,
            assigned_to="agent-001",
            created_at=datetime.now() - timedelta(days=2),
            updated_at=datetime.now(),
            due_date=datetime.now() + timedelta(days=5),
            estimated_hours=16.0,
            dependencies=["TASK-001"],
            labels=["backend", "security", "auth"]
        )
    
    @pytest.fixture
    def empty_task_list(self) -> List[Task]:
        """Create an empty task list."""
        return []
    
    @pytest.fixture
    def chaotic_task_list(self, basic_task) -> List[Task]:
        """Create a chaotic board with minimal task information."""
        tasks = []
        for i in range(15):
            task = Task(
                id=f"TASK-{i:03d}",
                name=f"Task {i}",
                description="",  # No descriptions
                status=TaskStatus.TODO,
                priority=Priority.MEDIUM,  # All same priority
                assigned_to=None,
                created_at=datetime.now(),
                updated_at=datetime.now(),
                due_date=None,
                estimated_hours=0.0,  # No estimates
                dependencies=[],
                labels=[]  # No labels
            )
            tasks.append(task)
        return tasks
    
    @pytest.fixture
    def well_structured_board(self) -> List[Task]:
        """Create a well-structured board with diverse tasks."""
        base_time = datetime.now()
        tasks = [
            Task(
                id="TASK-001",
                name="Setup project infrastructure",
                description="Initialize Docker containers, setup CI/CD pipeline with GitHub Actions, "
                           "and configure development environment variables.",
                status=TaskStatus.DONE,
                priority=Priority.HIGH,
                assigned_to="agent-001",
                created_at=base_time - timedelta(days=10),
                updated_at=base_time - timedelta(days=8),
                due_date=base_time - timedelta(days=7),
                estimated_hours=8.0,
                actual_hours=10.0,
                dependencies=[],
                labels=["infrastructure", "setup", "devops"]
            ),
            Task(
                id="TASK-002",
                name="Design database schema",
                description="Create ERD for user management, products, and orders. "
                           "Design indexes for optimal query performance.",
                status=TaskStatus.DONE,
                priority=Priority.HIGH,
                assigned_to="agent-002",
                created_at=base_time - timedelta(days=9),
                updated_at=base_time - timedelta(days=6),
                due_date=base_time - timedelta(days=5),
                estimated_hours=12.0,
                actual_hours=14.0,
                dependencies=["TASK-001"],
                labels=["database", "design", "backend"]
            ),
            Task(
                id="TASK-003",
                name="Implement user authentication",
                description="Build JWT-based authentication with refresh tokens. "
                           "Support email/password and OAuth2 providers.",
                status=TaskStatus.IN_PROGRESS,
                priority=Priority.HIGH,
                assigned_to="agent-003",
                created_at=base_time - timedelta(days=5),
                updated_at=base_time - timedelta(hours=2),
                due_date=base_time + timedelta(days=2),
                estimated_hours=20.0,
                actual_hours=8.0,
                dependencies=["TASK-002"],
                labels=["backend", "api", "security", "auth"]
            ),
            Task(
                id="TASK-004",
                name="Create React frontend scaffold",
                description="Setup React with TypeScript, configure Redux toolkit, "
                           "and implement routing with React Router v6.",
                status=TaskStatus.IN_PROGRESS,
                priority=Priority.MEDIUM,
                assigned_to="agent-004",
                created_at=base_time - timedelta(days=4),
                updated_at=base_time - timedelta(hours=1),
                due_date=base_time + timedelta(days=3),
                estimated_hours=16.0,
                actual_hours=4.0,
                dependencies=["TASK-001"],
                labels=["frontend", "react", "ui"]
            ),
            Task(
                id="TASK-005",
                name="Write unit tests for auth module",
                description="Achieve 90% test coverage for authentication endpoints. "
                           "Include edge cases and security tests.",
                status=TaskStatus.TODO,
                priority=Priority.MEDIUM,
                assigned_to=None,
                created_at=base_time - timedelta(days=2),
                updated_at=base_time - timedelta(days=2),
                due_date=base_time + timedelta(days=7),
                estimated_hours=8.0,
                dependencies=["TASK-003"],
                labels=["testing", "backend", "quality"]
            ),
            Task(
                id="TASK-006",
                name="Deploy to staging environment",
                description="Configure Kubernetes manifests and deploy application "
                           "to staging cluster for QA testing.",
                status=TaskStatus.TODO,
                priority=Priority.LOW,
                assigned_to=None,
                created_at=base_time - timedelta(days=1),
                updated_at=base_time - timedelta(days=1),
                due_date=base_time + timedelta(days=14),
                estimated_hours=6.0,
                dependencies=["TASK-003", "TASK-004", "TASK-005"],
                labels=["deployment", "devops", "infrastructure"]
            )
        ]
        return tasks
    
    @pytest.fixture
    def phased_workflow_board(self) -> List[Task]:
        """Create a board with clear phase-based workflow."""
        tasks = []
        phases = [
            ("setup", TaskStatus.DONE, ["setup", "config"]),
            ("design", TaskStatus.DONE, ["design", "architecture"]),
            ("development", TaskStatus.IN_PROGRESS, ["implement", "code"]),
            ("testing", TaskStatus.TODO, ["test", "qa"]),
            ("deployment", TaskStatus.TODO, ["deploy", "release"])
        ]
        
        for i, (phase, status, labels) in enumerate(phases):
            for j in range(3):
                task = Task(
                    id=f"TASK-{phase}-{j:02d}",
                    name=f"{phase.title()} task {j+1}",
                    description=f"Work on {phase} phase - task {j+1}",
                    status=status,
                    priority=Priority.MEDIUM,
                    assigned_to="agent-001" if status == TaskStatus.IN_PROGRESS else None,
                    created_at=datetime.now() - timedelta(days=20-i*3),
                    updated_at=datetime.now() - timedelta(days=20-i*3),
                    due_date=None,
                    estimated_hours=8.0,
                    dependencies=[],
                    labels=labels
                )
                tasks.append(task)
        
        return tasks
    
    # Test analyze_board method
    
    @pytest.mark.asyncio
    async def test_analyze_board_empty(self, analyzer: BoardAnalyzer, empty_task_list: List[Task]):
        """Test analyzing an empty board returns correct state."""
        result = await analyzer.analyze_board("test-board", empty_task_list)
        
        assert result.task_count == 0
        assert result.tasks_with_descriptions == 0
        assert result.tasks_with_labels == 0
        assert result.tasks_with_estimates == 0
        assert result.tasks_with_dependencies == 0
        assert result.structure_score == 0.0
        assert result.workflow_pattern == WorkflowPattern.UNKNOWN
        assert result.phases_detected == []
        assert result.components_detected == []
        assert result.metadata_completeness == 0.0
        assert result.is_empty is True
        assert result.is_chaotic is False
        assert result.is_well_structured is False
        assert result.recommended_mode == "creator"
    
    @pytest.mark.asyncio
    async def test_analyze_board_chaotic(self, analyzer: BoardAnalyzer, chaotic_task_list: List[Task]):
        """Test analyzing a chaotic board with minimal structure."""
        result = await analyzer.analyze_board("test-board", chaotic_task_list)
        
        assert result.task_count == 15
        assert result.tasks_with_descriptions == 0
        assert result.tasks_with_labels == 0
        assert result.tasks_with_estimates == 0
        assert result.tasks_with_dependencies == 0
        assert result.structure_score < 0.3
        assert result.workflow_pattern == WorkflowPattern.AD_HOC
        assert result.phases_detected == []
        assert result.components_detected == []
        assert result.metadata_completeness == 0.0
        assert result.is_empty is False
        assert result.is_chaotic is True
        assert result.is_well_structured is False
        assert result.recommended_mode == "enricher"
    
    @pytest.mark.asyncio
    async def test_analyze_board_well_structured(self, analyzer: BoardAnalyzer, well_structured_board: List[Task]):
        """Test analyzing a well-structured board with rich metadata."""
        result = await analyzer.analyze_board("test-board", well_structured_board)
        
        assert result.task_count == 6
        assert result.tasks_with_descriptions == 6
        assert result.tasks_with_labels == 6
        assert result.tasks_with_estimates == 6
        assert result.tasks_with_dependencies == 5  # 5 tasks have dependencies in the fixture
        assert result.structure_score >= 0.7
        assert result.workflow_pattern == WorkflowPattern.PHASED  # Has 5 phases detected
        assert "setup" in result.phases_detected
        assert "design" in result.phases_detected
        assert "development" in result.phases_detected
        assert "testing" in result.phases_detected
        assert "deployment" in result.phases_detected
        assert "backend" in result.components_detected
        assert "frontend" in result.components_detected
        assert "database" in result.components_detected
        assert "testing" in result.components_detected
        assert result.metadata_completeness > 0.5
        assert result.is_empty is False
        assert result.is_chaotic is False
        assert result.is_well_structured is True
        assert result.recommended_mode == "adaptive"
    
    @pytest.mark.asyncio
    async def test_analyze_board_single_task(self, analyzer: BoardAnalyzer, well_structured_task: Task):
        """Test analyzing a board with a single well-structured task."""
        result = await analyzer.analyze_board("test-board", [well_structured_task])
        
        assert result.task_count == 1
        assert result.tasks_with_descriptions == 1
        assert result.tasks_with_labels == 1
        assert result.tasks_with_estimates == 1
        assert result.tasks_with_dependencies == 1
        assert result.is_empty is False
        assert result.recommended_mode == "adaptive"  # Well-structured takes precedence
    
    # Test calculate_structure_score method
    
    @pytest.mark.asyncio
    async def test_calculate_structure_score_empty(self, analyzer: BoardAnalyzer):
        """Test structure score calculation for empty task list."""
        score = await analyzer.calculate_structure_score([])
        assert score == 0.0
    
    @pytest.mark.asyncio
    async def test_calculate_structure_score_minimal(self, analyzer: BoardAnalyzer, basic_task: Task):
        """Test structure score for tasks with minimal information."""
        tasks = [basic_task] * 5
        score = await analyzer.calculate_structure_score(tasks)
        
        # Should be low due to no descriptions, labels, estimates, or dependencies
        assert score < 0.3
    
    @pytest.mark.asyncio
    async def test_calculate_structure_score_partial(self, analyzer: BoardAnalyzer):
        """Test structure score for tasks with partial metadata."""
        tasks = []
        for i in range(10):
            task = Task(
                id=f"TASK-{i:03d}",
                name=f"Task {i}",
                description="Short desc" if i % 2 == 0 else "A much longer description that provides detailed information about what needs to be done",
                status=TaskStatus.TODO,
                priority=Priority.HIGH if i < 3 else Priority.MEDIUM if i < 7 else Priority.LOW,
                assigned_to=None,
                created_at=datetime.now(),
                updated_at=datetime.now(),
                due_date=None,
                estimated_hours=8.0 if i % 3 == 0 else 0.0,
                dependencies=["TASK-000"] if i > 5 else [],
                labels=["frontend", "api"] if i % 2 == 0 else []
            )
            tasks.append(task)
        
        score = await analyzer.calculate_structure_score(tasks)
        
        # Should be moderate due to partial metadata
        assert 0.3 <= score <= 0.7
    
    @pytest.mark.asyncio
    async def test_calculate_structure_score_excellent(self, analyzer: BoardAnalyzer, well_structured_board: List[Task]):
        """Test structure score for well-structured tasks."""
        score = await analyzer.calculate_structure_score(well_structured_board)
        
        # Should be high due to complete metadata
        assert score >= 0.7
    
    @pytest.mark.asyncio
    async def test_calculate_structure_score_priority_diversity(self, analyzer: BoardAnalyzer):
        """Test that priority diversity affects structure score."""
        # All same priority
        tasks_same = []
        for i in range(5):
            task = Task(
                id=f"TASK-{i:03d}",
                name=f"Task {i}",
                description="Good description with enough detail",
                status=TaskStatus.TODO,
                priority=Priority.MEDIUM,  # All same
                assigned_to=None,
                created_at=datetime.now(),
                updated_at=datetime.now(),
                due_date=None,
                estimated_hours=5.0,
                dependencies=[],
                labels=["test"]
            )
            tasks_same.append(task)
        
        # Diverse priorities
        tasks_diverse = []
        priorities = [Priority.LOW, Priority.MEDIUM, Priority.HIGH, Priority.URGENT, Priority.MEDIUM]
        for i, priority in enumerate(priorities):
            task = Task(
                id=f"TASK-{i:03d}",
                name=f"Task {i}",
                description="Good description with enough detail",
                status=TaskStatus.TODO,
                priority=priority,
                assigned_to=None,
                created_at=datetime.now(),
                updated_at=datetime.now(),
                due_date=None,
                estimated_hours=5.0,
                dependencies=[],
                labels=["test"]
            )
            tasks_diverse.append(task)
        
        score_same = await analyzer.calculate_structure_score(tasks_same)
        score_diverse = await analyzer.calculate_structure_score(tasks_diverse)
        
        # Diverse priorities should score higher
        assert score_diverse > score_same
    
    # Test detect_workflow_patterns method
    
    @pytest.mark.asyncio
    async def test_detect_workflow_empty(self, analyzer: BoardAnalyzer):
        """Test workflow detection for empty task list."""
        pattern = await analyzer.detect_workflow_patterns([])
        assert pattern == WorkflowPattern.UNKNOWN
    
    @pytest.mark.asyncio
    async def test_detect_workflow_sequential(self, analyzer: BoardAnalyzer):
        """Test detection of sequential workflow pattern."""
        tasks = []
        for i in range(10):
            status = TaskStatus.DONE if i < 5 else TaskStatus.IN_PROGRESS if i == 5 else TaskStatus.TODO
            task = Task(
                id=f"TASK-{i:03d}",
                name=f"Sequential task {i}",
                description="Task description",
                status=status,
                priority=Priority.MEDIUM,
                assigned_to="agent-001" if status == TaskStatus.IN_PROGRESS else None,
                created_at=datetime.now(),
                updated_at=datetime.now(),
                due_date=None,
                estimated_hours=4.0,
                dependencies=[f"TASK-{i-1:03d}"] if i > 0 else [],
                labels=[]
            )
            tasks.append(task)
        
        pattern = await analyzer.detect_workflow_patterns(tasks)
        assert pattern == WorkflowPattern.SEQUENTIAL
    
    @pytest.mark.asyncio
    async def test_detect_workflow_parallel(self, analyzer: BoardAnalyzer):
        """Test detection of parallel workflow pattern."""
        tasks = []
        for i in range(10):
            # 4 tasks in progress simultaneously
            status = TaskStatus.IN_PROGRESS if 3 <= i <= 6 else TaskStatus.TODO
            task = Task(
                id=f"TASK-{i:03d}",
                name=f"Parallel task {i}",
                description="Task description",
                status=status,
                priority=Priority.MEDIUM,
                assigned_to=f"agent-{i:03d}" if status == TaskStatus.IN_PROGRESS else None,
                created_at=datetime.now(),
                updated_at=datetime.now(),
                due_date=None,
                estimated_hours=4.0,
                dependencies=[],
                labels=[]
            )
            tasks.append(task)
        
        pattern = await analyzer.detect_workflow_patterns(tasks)
        assert pattern == WorkflowPattern.PARALLEL
    
    @pytest.mark.asyncio
    async def test_detect_workflow_phased(self, analyzer: BoardAnalyzer, phased_workflow_board: List[Task]):
        """Test detection of phased workflow pattern."""
        pattern = await analyzer.detect_workflow_patterns(phased_workflow_board)
        # Should detect phased due to clear phase structure
        assert pattern == WorkflowPattern.PHASED
    
    @pytest.mark.asyncio
    async def test_detect_workflow_ad_hoc_no_progress(self, analyzer: BoardAnalyzer):
        """Test ad-hoc pattern when no tasks are in progress."""
        tasks = []
        for i in range(8):
            task = Task(
                id=f"TASK-{i:03d}",
                name=f"Random task {i}",
                description="",
                status=TaskStatus.TODO,
                priority=Priority.MEDIUM,
                assigned_to=None,
                created_at=datetime.now(),
                updated_at=datetime.now(),
                due_date=None,
                estimated_hours=0.0,
                dependencies=[],
                labels=[]
            )
            tasks.append(task)
        
        pattern = await analyzer.detect_workflow_patterns(tasks)
        assert pattern == WorkflowPattern.AD_HOC
    
    # Test phase detection
    
    @pytest.mark.asyncio
    async def test_detect_phases_empty(self, analyzer: BoardAnalyzer):
        """Test phase detection with empty task list."""
        phases = await analyzer._detect_phases([])
        assert phases == []
    
    @pytest.mark.asyncio
    async def test_detect_phases_from_names(self, analyzer: BoardAnalyzer):
        """Test phase detection from task names."""
        tasks = [
            self._create_task("Setup CI/CD pipeline", ""),
            self._create_task("Design system architecture", ""),
            self._create_task("Implement core features", ""),
            self._create_task("Write unit tests", ""),
            self._create_task("Deploy to production", ""),
            self._create_task("Fix critical bugs", "")
        ]
        
        phases = await analyzer._detect_phases(tasks)
        
        assert "setup" in phases
        assert "design" in phases
        assert "development" in phases
        assert "testing" in phases
        assert "deployment" in phases
        assert "maintenance" in phases
        
        # Check ordering
        assert phases.index("setup") < phases.index("design")
        assert phases.index("design") < phases.index("development")
        assert phases.index("development") < phases.index("testing")
    
    @pytest.mark.asyncio
    async def test_detect_phases_from_descriptions(self, analyzer: BoardAnalyzer):
        """Test phase detection from task descriptions."""
        tasks = [
            self._create_task("Task 1", "Initialize project configuration and environment"),
            self._create_task("Task 2", "Plan database schema and API architecture"),
            self._create_task("Task 3", "Build user authentication module"),
            self._create_task("Task 4", "Validate all endpoints with integration tests"),
            self._create_task("Task 5", "Ship to production servers")
        ]
        
        phases = await analyzer._detect_phases(tasks)
        
        assert "setup" in phases
        assert "design" in phases
        assert "development" in phases
        assert "testing" in phases
        assert "deployment" in phases
    
    @pytest.mark.asyncio
    async def test_detect_phases_case_insensitive(self, analyzer: BoardAnalyzer):
        """Test that phase detection is case insensitive."""
        tasks = [
            self._create_task("SETUP database", "INITIALIZE the system"),
            self._create_task("Design UI", "ARCHITECT the solution"),
            self._create_task("IMPLEMENT features", "BUILD the app")
        ]
        
        phases = await analyzer._detect_phases(tasks)
        
        assert "setup" in phases
        assert "design" in phases
        assert "development" in phases
    
    # Test component detection
    
    @pytest.mark.asyncio
    async def test_detect_components_empty(self, analyzer: BoardAnalyzer):
        """Test component detection with empty task list."""
        components = await analyzer._detect_components([])
        assert components == []
    
    @pytest.mark.asyncio
    async def test_detect_components_from_names(self, analyzer: BoardAnalyzer):
        """Test component detection from task names."""
        tasks = [
            self._create_task("Build React dashboard", ""),
            self._create_task("Create REST API endpoints", ""),
            self._create_task("Setup PostgreSQL database", ""),
            self._create_task("Configure Docker containers", ""),
            self._create_task("Develop iOS application", ""),
            self._create_task("Write integration tests", "")
        ]
        
        components = await analyzer._detect_components(tasks)
        
        assert "frontend" in components
        assert "backend" in components
        assert "database" in components
        assert "infrastructure" in components
        assert "mobile" in components
        assert "testing" in components
    
    @pytest.mark.asyncio
    async def test_detect_components_from_labels(self, analyzer: BoardAnalyzer):
        """Test component detection from task labels."""
        tasks = [
            self._create_task_with_labels("Task 1", "", ["ui", "react"]),
            self._create_task_with_labels("Task 2", "", ["api", "nodejs"]),
            self._create_task_with_labels("Task 3", "", ["mongodb", "cache"]),
            self._create_task_with_labels("Task 4", "", ["k8s", "ci/cd"]),
            self._create_task_with_labels("Task 5", "", ["android", "kotlin"]),
            self._create_task_with_labels("Task 6", "", ["e2e", "jest"])
        ]
        
        components = await analyzer._detect_components(tasks)
        
        assert "frontend" in components
        assert "backend" in components
        assert "database" in components
        assert "infrastructure" in components
        assert "mobile" in components
        assert "testing" in components
    
    @pytest.mark.asyncio
    async def test_detect_components_sorted(self, analyzer: BoardAnalyzer):
        """Test that detected components are sorted."""
        tasks = [
            self._create_task("Testing framework", ""),
            self._create_task("Mobile app", ""),
            self._create_task("Frontend UI", ""),
            self._create_task("Backend API", ""),
            self._create_task("Database schema", "")
        ]
        
        components = await analyzer._detect_components(tasks)
        
        # Should be alphabetically sorted
        assert components == sorted(components)
    
    # Test mode recommendation
    
    def test_recommend_mode_empty_board(self, analyzer: BoardAnalyzer):
        """Test mode recommendation for empty board."""
        mode = analyzer._recommend_mode(
            is_empty=True,
            is_chaotic=False,
            is_well_structured=False,
            task_count=0
        )
        assert mode == "creator"
    
    def test_recommend_mode_chaotic_large(self, analyzer: BoardAnalyzer):
        """Test mode recommendation for large chaotic board."""
        mode = analyzer._recommend_mode(
            is_empty=False,
            is_chaotic=True,
            is_well_structured=False,
            task_count=25
        )
        assert mode == "enricher"
    
    def test_recommend_mode_chaotic_small(self, analyzer: BoardAnalyzer):
        """Test mode recommendation for small chaotic board."""
        mode = analyzer._recommend_mode(
            is_empty=False,
            is_chaotic=True,
            is_well_structured=False,
            task_count=3
        )
        assert mode == "creator"  # Few tasks override chaotic
    
    def test_recommend_mode_well_structured(self, analyzer: BoardAnalyzer):
        """Test mode recommendation for well-structured board."""
        mode = analyzer._recommend_mode(
            is_empty=False,
            is_chaotic=False,
            is_well_structured=True,
            task_count=20
        )
        assert mode == "adaptive"
    
    def test_recommend_mode_medium_board(self, analyzer: BoardAnalyzer):
        """Test mode recommendation for medium-structured board."""
        mode = analyzer._recommend_mode(
            is_empty=False,
            is_chaotic=False,
            is_well_structured=False,
            task_count=8
        )
        assert mode == "enricher"
    
    # Test edge cases and error scenarios
    
    @pytest.mark.asyncio
    async def test_analyze_board_with_none_values(self, analyzer: BoardAnalyzer):
        """Test board analysis handles tasks with None values gracefully."""
        # According to the Task dataclass, labels and dependencies have default_factory=list
        # So they should never be None in practice. Let's test with realistic None values
        tasks = [
            Task(
                id="TASK-001",
                name="Task with nulls",
                description=None,  # None description - this is allowed
                status=TaskStatus.TODO,
                priority=Priority.MEDIUM,  # Priority is required, can't be None
                assigned_to=None,
                created_at=datetime.now(),
                updated_at=datetime.now(),
                due_date=None,
                estimated_hours=0.0,  # Using 0 instead of None
                dependencies=[],  # Uses default factory
                labels=[]  # Uses default factory
            )
        ]
        
        # Should handle gracefully without errors
        result = await analyzer.analyze_board("test-board", tasks)
        assert result.task_count == 1
        assert result.tasks_with_descriptions == 0
        assert result.tasks_with_estimates == 0
        assert result.tasks_with_labels == 0
    
    @pytest.mark.asyncio
    async def test_board_analyzer_defensive_none_handling(self, analyzer: BoardAnalyzer):
        """Test that board analyzer handles None labels/dependencies defensively."""
        # Even though Task dataclass has default factories, test defensive coding
        # by manually setting None values (simulating external data corruption)
        task = Task(
            id="TASK-001",
            name="Corrupted task",
            description="Test task",
            status=TaskStatus.TODO,
            priority=Priority.MEDIUM,
            assigned_to=None,
            created_at=datetime.now(),
            updated_at=datetime.now(),
            due_date=None,
            estimated_hours=5.0,
            dependencies=[],
            labels=[]
        )
        
        # Manually corrupt the task data
        task.labels = None
        task.dependencies = None
        
        # The current implementation will fail with TypeError
        # This test documents the current behavior
        with pytest.raises(TypeError):
            await analyzer.calculate_structure_score([task])
    
    @pytest.mark.asyncio
    async def test_phase_detection_regex_patterns(self, analyzer: BoardAnalyzer):
        """Test that phase regex patterns work correctly."""
        # Test each phase pattern
        test_cases = [
            ("setup", ["setup project", "init system", "initialize app", "config server", "configure db", "scaffold ui"]),
            ("design", ["design api", "architect system", "plan features", "model data", "schema creation"]),
            ("development", ["implement auth", "build ui", "create api", "develop feature", "code review"]),
            ("testing", ["test endpoints", "qa process", "quality check", "verify data", "validate input"]),
            ("deployment", ["deploy app", "release v1", "launch product", "ship to prod", "production ready"]),
            ("maintenance", ["maintain code", "fix bugs", "bug fixes", "patch security", "update deps"])
        ]
        
        for expected_phase, task_names in test_cases:
            tasks = [self._create_task(name, "") for name in task_names]
            phases = await analyzer._detect_phases(tasks)
            assert expected_phase in phases, f"Failed to detect {expected_phase} phase"
    
    @pytest.mark.asyncio
    async def test_component_detection_regex_patterns(self, analyzer: BoardAnalyzer):
        """Test that component regex patterns work correctly."""
        # Test each component pattern
        test_cases = [
            ("frontend", ["frontend work", "ui design", "client app", "react component", "vue page", "angular service"]),
            ("backend", ["backend api", "api endpoint", "server logic", "endpoint creation", "service layer"]),
            ("database", ["database setup", "db migration", "sql query", "mongo collection", "redis cache", "cache layer"]),
            ("infrastructure", ["infra setup", "devops work", "ci pipeline", "cd process", "docker config", "k8s deploy"]),
            ("mobile", ["mobile app", "ios feature", "android ui", "app store", "native code"]),
            ("testing", ["test suite", "spec file", "e2e test", "unit test", "integration test"])
        ]
        
        for expected_component, task_names in test_cases:
            tasks = [self._create_task(name, "") for name in task_names]
            components = await analyzer._detect_components(tasks)
            assert expected_component in components, f"Failed to detect {expected_component} component"
    
    @pytest.mark.asyncio
    async def test_workflow_pattern_edge_cases(self, analyzer: BoardAnalyzer):
        """Test workflow pattern detection edge cases."""
        # Test with exactly 3 in-progress (boundary for parallel)
        tasks = []
        for i in range(10):
            status = TaskStatus.IN_PROGRESS if i < 3 else TaskStatus.TODO
            tasks.append(self._create_task(f"Task {i}", "", status=status))
        
        pattern = await analyzer.detect_workflow_patterns(tasks)
        assert pattern == WorkflowPattern.AD_HOC  # Not quite parallel (needs >3)
        
        # Test with exactly 4 in-progress (should be parallel)
        tasks[3].status = TaskStatus.IN_PROGRESS
        pattern = await analyzer.detect_workflow_patterns(tasks)
        assert pattern == WorkflowPattern.PARALLEL
    
    @pytest.mark.asyncio
    async def test_calculate_structure_score_no_priorities(self, analyzer: BoardAnalyzer):
        """Test structure score when tasks have no priorities."""
        tasks = []
        for i in range(3):
            task = Task(
                id=f"TASK-{i:03d}",
                name=f"Task {i}",
                description="Good description with details",
                status=TaskStatus.TODO,
                priority=None,  # No priority set
                assigned_to=None,
                created_at=datetime.now(),
                updated_at=datetime.now(),
                due_date=None,
                estimated_hours=8.0,
                dependencies=[],
                labels=["test", "important"]
            )
            tasks.append(task)
        
        score = await analyzer.calculate_structure_score(tasks)
        # Should handle missing priorities gracefully
        assert score > 0  # Should still have score from other components
    
    @pytest.mark.asyncio
    async def test_structure_score_components(self, analyzer: BoardAnalyzer):
        """Test individual components of structure score calculation."""
        # Task with only long description
        task_desc = Task(
            id="T1",
            name="Task",
            description="A" * 60,  # Long description
            status=TaskStatus.TODO,
            priority=Priority.MEDIUM,
            assigned_to=None,
            created_at=datetime.now(),
            updated_at=datetime.now(),
            due_date=None,
            estimated_hours=0.0,
            dependencies=[],
            labels=[]
        )
        
        score = await analyzer.calculate_structure_score([task_desc])
        assert score > 0  # Should have some score from description
        
        # Task with only labels
        task_labels = Task(
            id="T2",
            name="Task",
            description="",
            status=TaskStatus.TODO,
            priority=Priority.MEDIUM,
            assigned_to=None,
            created_at=datetime.now(),
            updated_at=datetime.now(),
            due_date=None,
            estimated_hours=0.0,
            dependencies=[],
            labels=["frontend", "urgent", "bug"]  # Multiple labels
        )
        
        score = await analyzer.calculate_structure_score([task_labels])
        assert score > 0  # Should have some score from labels
    
    # Helper methods
    
    def _create_task(self, name: str, description: str, status: TaskStatus = TaskStatus.TODO) -> Task:
        """Helper to create a task with minimal fields."""
        return Task(
            id=f"TASK-{hash(name) % 1000:03d}",
            name=name,
            description=description,
            status=status,
            priority=Priority.MEDIUM,
            assigned_to=None,
            created_at=datetime.now(),
            updated_at=datetime.now(),
            due_date=None,
            estimated_hours=0.0,
            dependencies=[],
            labels=[]
        )
    
    def _create_task_with_labels(self, name: str, description: str, labels: List[str]) -> Task:
        """Helper to create a task with specific labels."""
        task = self._create_task(name, description)
        task.labels = labels
        return task


class TestBoardStateDataclass:
    """Test suite for BoardState dataclass."""
    
    def test_board_state_creation(self):
        """Test BoardState can be created with all fields."""
        state = BoardState(
            task_count=10,
            tasks_with_descriptions=8,
            tasks_with_labels=7,
            tasks_with_estimates=6,
            tasks_with_dependencies=5,
            structure_score=0.75,
            workflow_pattern=WorkflowPattern.PHASED,
            phases_detected=["setup", "development"],
            components_detected=["frontend", "backend"],
            metadata_completeness=0.8,
            is_empty=False,
            is_chaotic=False,
            is_well_structured=True,
            recommended_mode="adaptive"
        )
        
        assert state.task_count == 10
        assert state.structure_score == 0.75
        assert state.workflow_pattern == WorkflowPattern.PHASED
        assert len(state.phases_detected) == 2
        assert len(state.components_detected) == 2
        assert state.is_well_structured is True
        assert state.recommended_mode == "adaptive"


class TestWorkflowPatternEnum:
    """Test suite for WorkflowPattern enum."""
    
    def test_workflow_pattern_values(self):
        """Test WorkflowPattern enum has expected values."""
        assert WorkflowPattern.SEQUENTIAL.value == "sequential"
        assert WorkflowPattern.PARALLEL.value == "parallel"
        assert WorkflowPattern.PHASED.value == "phased"
        assert WorkflowPattern.AD_HOC.value == "ad_hoc"
        assert WorkflowPattern.UNKNOWN.value == "unknown"
    
    def test_workflow_pattern_members(self):
        """Test all WorkflowPattern members are accessible."""
        patterns = [p for p in WorkflowPattern]
        assert len(patterns) == 5
        assert WorkflowPattern.SEQUENTIAL in patterns
        assert WorkflowPattern.PARALLEL in patterns
        assert WorkflowPattern.PHASED in patterns
        assert WorkflowPattern.AD_HOC in patterns
        assert WorkflowPattern.UNKNOWN in patterns